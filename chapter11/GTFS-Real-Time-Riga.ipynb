{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "## 11.5. GTFS Realtime Analysis of the City of Riga"
   ]
  },
{
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb15fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gtfs-realtime-bindings requests pandas plotly pyarrow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyarrow==10.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyarrow \n",
    "#Not working for Mac M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e830cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from google.transit import gtfs_realtime_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "858e43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# 11.4. GTFS-Realtime URL for Riga"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# Section 11.4.1. Part 1 - Ingesting GTFS Realtime Feed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9be94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.4. GTFS-Realtime URL for Riga\n",
    "# Section 11.4.1. - Ingesting GTFS Realtime Feed - Part 1\n",
    "\n",
    "GTFS_REALTIME_URL = \"https://saraksti.rigassatiksme.lv/gtfs_realtime.pb\"\n",
    "\n",
    "# Function to fetch GTFS-Realtime data\n",
    "def fetch_gtfs_realtime_data(url):\n",
    "    \"\"\"\n",
    "    Fetches the GTFS-Realtime data from the given URL with SSL verification disabled.\n",
    "    \n",
    "    Parameters:\n",
    "    - url: The GTFS-Realtime endpoint URL\n",
    "    \n",
    "    Returns:\n",
    "    - feed: Parsed GTFS-Realtime protobuf feed\n",
    "    \"\"\"\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    \n",
    "    try:\n",
    "        # Disable SSL verification\n",
    "        response = requests.get(url, verify=False)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "\n",
    "        # Parse the protobuf data\n",
    "        feed.ParseFromString(response.content)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching GTFS-Realtime data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return feed"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# Section 11.4.1. Part 2 - Function to extract vehicle positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "183546d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 11.4.1. - Part 2 - Function to extract vehicle positions \n",
    "\n",
    "def extract_vehicle_positions(feed):\n",
    "    \"\"\"\n",
    "    Extracts vehicle positions from the GTFS-Realtime feed.\n",
    "    \n",
    "    Parameters:\n",
    "    - feed: Parsed GTFS-Realtime protobuf feed\n",
    "    \n",
    "    Returns:\n",
    "    - List of dictionaries containing vehicle positions and trip information\n",
    "    \"\"\"\n",
    "    vehicle_position = []\n",
    "    for entity in feed.entity:\n",
    "        if entity.HasField('vehicle'):\n",
    "            vehicle = entity.vehicle\n",
    "            vehicle_position.append({\n",
    "                \"id\": entity.id,\n",
    "                \"trip_id\": vehicle.trip.trip_id,\n",
    "                \"schedule_relationship\": vehicle.trip.schedule_relationship,\n",
    "                \"latitude\": vehicle.position.latitude,\n",
    "                \"longitude\": vehicle.position.longitude,\n",
    "                \"bearing\": vehicle.position.bearing,\n",
    "                \"speed\": vehicle.position.speed * 3.6,  # Speed in km/h\n",
    "                \"current_status\": vehicle.current_status,\n",
    "                \"timestamp\": vehicle.timestamp,\n",
    "                \"stop_id\": vehicle.stop_id,\n",
    "                \"vehicle_id\": vehicle.vehicle.id,\n",
    "                \"vehicle_label\": vehicle.vehicle.label,\n",
    "                \"vehicle_license_plate\": vehicle.vehicle.license_plate       \n",
    "            })\n",
    "    return vehicle_position"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# 11.4.2. Parquet Files and DuckDB for Mobility Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 11.4.2. Parquet Files and DuckDB for Mobility Data\n",
    "# Function to collect vehicle positions for a specific duration and save into a Parquet File\n",
    "\n",
    "def collect_vehicle_positions(duration_minutes, interval_seconds):\n",
    "    \"\"\"\n",
    "    Collects vehicle positions from the GTFS-Realtime endpoint at regular intervals.\n",
    "    \n",
    "    Parameters:\n",
    "    - duration_minutes: Duration of the collection period in minutes\n",
    "    - interval_seconds: Interval between successive API calls in seconds\n",
    "    \n",
    "    Returns:\n",
    "    - A DataFrame containing all collected vehicle positions\n",
    "    \"\"\"\n",
    "    collected_data = []\n",
    "    end_time = time.time() + duration_minutes * 60  # Convert minutes to seconds\n",
    "\n",
    "    while time.time() < end_time:\n",
    "        # Fetch the GTFS-Realtime data\n",
    "        feed = fetch_gtfs_realtime_data(GTFS_REALTIME_URL)\n",
    "\n",
    "        # If feed is fetched, extract vehicle positions\n",
    "        if feed:\n",
    "            vehicle_positions = extract_vehicle_positions(feed)\n",
    "            if vehicle_positions:\n",
    "                collected_data.extend(vehicle_positions)  # Add the new data to the list\n",
    "                print(f\"Collected {len(vehicle_positions)} vehicle positions.\")\n",
    "            else:\n",
    "                print(\"No vehicle positions found in the feed.\")\n",
    "        else:\n",
    "            print(\"Failed to fetch the GTFS-Realtime feed.\")\n",
    "        \n",
    "        # Wait for the specified interval before making the next request\n",
    "        time.sleep(interval_seconds)\n",
    "    \n",
    "    # Convert the collected data into a DataFrame\n",
    "    df = pd.DataFrame(collected_data)\n",
    "    return df\n",
    "\n",
    "# Function to save DataFrame to a Parquet file\n",
    "def save_to_parquet(df, file_name):\n",
    "    \"\"\"\n",
    "    Saves the collected vehicle data to a Parquet file.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The DataFrame containing the vehicle positions data\n",
    "    - file_name: The name of the output Parquet file\n",
    "    \"\"\"\n",
    "    if not df.empty:\n",
    "        table = pa.Table.from_pandas(df)\n",
    "        pq.write_table(table, file_name)\n",
    "        print(f\"Data successfully saved to {file_name}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "        \n",
    "        \n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    DURATION_MINUTES = 60  # Collect data for 1 hour\n",
    "    INTERVAL_SECONDS = 10   # Call the endpoint every 10 seconds\n",
    "\n",
    "    # Collect vehicle positions over the specified duration\n",
    "    print(f\"Starting data collection for {DURATION_MINUTES} minutes, querying every {INTERVAL_SECONDS} seconds...\")\n",
    "    vehicle_positions_df = collect_vehicle_positions(DURATION_MINUTES, INTERVAL_SECONDS)\n",
    "\n",
    "    # Save the data to a Parquet file\n",
    "    output_file = \"riga_vehicle_positions_test.parquet\"\n",
    "    save_to_parquet(vehicle_positions_df, output_file)"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# 11.4.3. Querying and Visualizing Vehicle Trajectories with Parquet Files and DuckDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 11.4.3. Querying and Visualizing Vehicle Trajectories with Parquet Files and DuckDB\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Path to the Parquet file\n",
    "parquet_file = \"/Users/avaisman/tmp/PythonNotebooks/riga_vehicle_positions.parquet\"\n",
    "\n",
    "# Function to load the parquet file and query the trajectory of Tram 1\n",
    "def query_tram1_trajectory(parquet_file):\n",
    "    \"\"\"\n",
    "    Queries the trajectory of Tram 1 from the parquet file using DuckDB.\n",
    "    \n",
    "    Parameters:\n",
    "    - parquet_file: Path to the Parquet file\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing the trajectory of Tram 1\n",
    "    \"\"\"\n",
    "    # Connect to DuckDB in-memory database\n",
    "    con = duckdb.connect()\n",
    "\n",
    "    # Load the parquet file and query for Tram 1 (Assuming Tram 1 is identified by route_id or trip_id)\n",
    "    # Adjust the condition to match the identifier for Tram 1\n",
    "    query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM parquet_scan('{parquet_file}')\n",
    "    WHERE trip_id LIKE '%TRAM1-%'  -- Adjust based on actual trip_id or route_id for Tram 1\n",
    "    ORDER BY timestamp\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and return the result as a pandas DataFrame\n",
    "    df = con.execute(query).fetchdf()\n",
    "\n",
    "    # Close the connection\n",
    "    con.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to visualize the trajectory of Tram 1\n",
    "def visualize_tram1_trajectory(df):\n",
    "    \"\"\"\n",
    "    Visualizes the trajectory of Tram 1 using Plotly.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the trajectory of Tram 1\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data available for Tram 1.\")\n",
    "        return\n",
    "    \n",
    "    fig = px.scatter_mapbox(df, lat=\"latitude\", lon=\"longitude\", \n",
    "                            hover_name=\"vehicle_id\", \n",
    "                            hover_data=[\"trip_id\", \"speed\"],\n",
    "                            color=\"timestamp\", \n",
    "                            color_continuous_scale=\"Viridis\",\n",
    "                            title=\"Trajectory of Tram 1\",\n",
    "                            zoom=12)\n",
    "\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\", mapbox_zoom=12, mapbox_center={\"lat\": 56.9496, \"lon\": 24.1052})\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and query the trajectory of Tram 1\n",
    "    tram1_df = query_tram1_trajectory(parquet_file)\n",
    "    \n",
    "    if not tram1_df.empty:\n",
    "        # Visualize the trajectory of Tram 1\n",
    "        visualize_tram1_trajectory(tram1_df)\n",
    "    else:\n",
    "        print(\"No data found for Tram 1.\")"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# 11.4.4 Querying and Visualizing Vehicle Trajectories with PostgreSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87777c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11.4.4 Querying and Visualizing Vehicle Trajectories with PostgreSQL\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "\n",
    "# PostgreSQL connection details\n",
    "db_host = \"localhost\"\n",
    "db_port = \"5432\"\n",
    "db_user = \"postgres\"\n",
    "db_pass = \"postgres\"\n",
    "db_name = \"UrbanMobility\"\n",
    "\n",
    "\n",
    "# Function to connect to the PostgreSQL database\n",
    "def connect_to_postgres():\n",
    "    \"\"\"\n",
    "    Establishes a connection to the PostgreSQL database.\n",
    "    \n",
    "    Returns:\n",
    "    - conn: The PostgreSQL connection object\n",
    "    - cur: The cursor object for executing SQL queries\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg.connect(\n",
    "            host=db_host,\n",
    "            port=db_port,\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_pass\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        return conn, cur\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to PostgreSQL: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to create the 'vehiclePosition' table in PostgreSQL\n",
    "\n",
    "def create_vehicle_position_table(cur):\n",
    "    \"\"\"\n",
    "    Creates the 'vehiclePosition' table in PostgreSQL if it doesn't exist.\n",
    "    \n",
    "    Parameters:\n",
    "    - cur: The cursor object for executing SQL queries\n",
    "    \"\"\"\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS vehiclePosition (\n",
    "        id TEXT,\n",
    "        trip_id TEXT,\n",
    "        schedule_relationship TEXT,\n",
    "        latitude FLOAT8,\n",
    "        longitude FLOAT8,\n",
    "        bearing FLOAT8,\n",
    "        speed FLOAT8,  -- Speed in kilometers per hour (km/h)\n",
    "        current_status TEXT,\n",
    "        timestamp BIGINT,\n",
    "        stop_id TEXT,\n",
    "        vehicle_id TEXT,\n",
    "        vehicle_label TEXT,\n",
    "        vehicle_license_plate TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "    cur.execute(create_table_query)\n",
    "\n",
    "# Function to load the Parquet file into a Pandas DataFrame\n",
    "def load_parquet_file(parquet_file):\n",
    "    \"\"\"\n",
    "    Loads the Parquet file into a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - parquet_file: Path to the Parquet file\n",
    "    \n",
    "    Returns:\n",
    "    - df: DataFrame containing the vehicle positions data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet(parquet_file)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Parquet file: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to insert the DataFrame data into the PostgreSQL 'vehiclePosition' table\n",
    "def insert_data_to_postgres(df, cur, conn):\n",
    "    \"\"\"\n",
    "    Inserts the data from the DataFrame into the PostgreSQL 'vehiclePosition' table.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The DataFrame containing the vehicle positions data\n",
    "    - cur: The cursor object for executing SQL queries\n",
    "    - conn: The PostgreSQL connection object\n",
    "    \"\"\"\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO vehiclePosition (id, trip_id, schedule_relationship, latitude, longitude, bearing, speed,\n",
    "                                 current_status, timestamp, stop_id, vehicle_id, vehicle_label, vehicle_license_plate)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "    \n",
    "    # Iterate over the DataFrame rows and insert them into the database\n",
    "    for _, row in df.iterrows():\n",
    "        cur.execute(insert_query, (\n",
    "            row['id'],\n",
    "            row['trip_id'],\n",
    "            row['schedule_relationship'],\n",
    "            row['latitude'],\n",
    "            row['longitude'],\n",
    "            row['bearing'],\n",
    "            row['speed'],\n",
    "            row['current_status'],\n",
    "            row['timestamp'],\n",
    "            row['stop_id'],\n",
    "            row['vehicle_id'],\n",
    "            row['vehicle_label'],\n",
    "            row['vehicle_license_plate']\n",
    "        ))\n",
    "    \n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Connect to PostgreSQL\n",
    "    conn, cur = connect_to_postgres()\n",
    "    if conn is None or cur is None:\n",
    "        print(\"Failed to connect to the PostgreSQL database.\")\n",
    "        exit()\n",
    "    \n",
    "    # Step 2: Create the 'vehiclePosition' table if it doesn't exist\n",
    "    print(\"Creating 'vehiclePosition' table if it doesn't exist...\")\n",
    "    create_vehicle_position_table(cur)\n",
    "    \n",
    "    # Step 3: Load the Parquet file into a DataFrame\n",
    "    print(\"Loading Parquet file...\")\n",
    "    vehicle_positions_df = load_parquet_file(parquet_file)\n",
    "    \n",
    "    if not vehicle_positions_df.empty:\n",
    "        print(f\"Loaded {len(vehicle_positions_df)} rows from the Parquet file.\")\n",
    "        \n",
    "        # Step 4: Insert the data into the PostgreSQL 'vehiclePosition' table\n",
    "        print(\"Inserting data into PostgreSQL...\")\n",
    "        insert_data_to_postgres(vehicle_positions_df, cur, conn)\n",
    "        print(\"Data insertion complete.\")\n",
    "    else:\n",
    "        print(\"No data found in the Parquet file.\")\n",
    "    \n",
    "    # Step 5: Close the PostgreSQL connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"PostgreSQL connection closed.\")"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# 11.4.4 Dash Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7bddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 11.4.4. Dash Visualizations\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "\n",
    "# Function to connect to the PostgreSQL database\n",
    "def connect_to_postgres():\n",
    "    try:\n",
    "        conn = psycopg.connect(\n",
    "            host=db_host,\n",
    "            port=db_port,\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_pass\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        return conn, cur\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to PostgreSQL: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to fetch available trip_ids from PostgreSQL\n",
    "def fetch_trip_ids():\n",
    "    conn, cur = connect_to_postgres()\n",
    "    if conn is None or cur is None:\n",
    "        return []\n",
    "\n",
    "    trip_id_query = \"SELECT DISTINCT trip_id FROM vehiclePosition;\"\n",
    "    cur.execute(trip_id_query)\n",
    "    trip_ids = [row[0] for row in cur.fetchall()]\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return trip_ids\n",
    "\n",
    "# Function to fetch vehicle positions for a specific trip_id\n",
    "def fetch_vehicle_positions(trip_id):\n",
    "    conn, cur = connect_to_postgres()\n",
    "    if conn is None or cur is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT latitude, longitude, vehicle_id, speed, timestamp\n",
    "    FROM vehiclePosition\n",
    "    WHERE trip_id = %s\n",
    "    ORDER BY timestamp;\n",
    "    \"\"\"\n",
    "    \n",
    "    cur.execute(query, (trip_id,))\n",
    "    vehicle_positions = pd.DataFrame(cur.fetchall(), columns=['latitude', 'longitude', 'vehicle_id', 'speed', 'timestamp'])\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return vehicle_positions\n",
    "\n",
    "# Dash app layout\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Get initial trip_ids to populate the dropdown\n",
    "trip_ids = fetch_trip_ids()\n",
    "\n",
    "# Set default trip_id (first one in the list)\n",
    "initial_trip_id = trip_ids[0] if trip_ids else None\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    html.H1(\"Vehicle Position Visualization\"),\n",
    "    \n",
    "    # Dropdown for selecting trip_id\n",
    "    dcc.Dropdown(\n",
    "        id=\"trip-dropdown\",\n",
    "        options=[{'label': trip_id, 'value': trip_id} for trip_id in trip_ids],\n",
    "        value=initial_trip_id,  # Default to the first trip_id\n",
    "        clearable=False,\n",
    "        style={\"width\": \"80%\"}\n",
    "    ),\n",
    "    \n",
    "    # Graph to display vehicle positions\n",
    "    dcc.Graph(id=\"vehicle-map\")\n",
    "])\n",
    "\n",
    "# Callback to update map based on selected trip_id\n",
    "@app.callback(\n",
    "    Output(\"vehicle-map\", \"figure\"),\n",
    "    Input(\"trip-dropdown\", \"value\")\n",
    ")\n",
    "def update_map(trip_id):\n",
    "    if trip_id is None:\n",
    "        return px.scatter_mapbox()  # Empty map if no trip_id is selected\n",
    "\n",
    "    # Fetch vehicle positions for the selected trip_id\n",
    "    vehicle_positions_df = fetch_vehicle_positions(trip_id)\n",
    "    \n",
    "    if vehicle_positions_df.empty:\n",
    "        return px.scatter_mapbox()  # Return empty map if no data\n",
    "\n",
    "    # Create a map visualization using Plotly\n",
    "    fig = px.scatter_mapbox(vehicle_positions_df, \n",
    "                            lat=\"latitude\", lon=\"longitude\", \n",
    "                            hover_name=\"vehicle_id\", \n",
    "                            hover_data=[\"speed\", \"timestamp\"],\n",
    "                            title=f\"Vehicle Positions for {trip_id}\",\n",
    "                            zoom=12)\n",
    "    fig.update_traces(marker=dict(size=10, color='red'))  # Increase the size and set color to red\n",
    "        \n",
    "    fig.update_layout(mapbox_style=\"open-street-map\", \n",
    "                      mapbox_center={\"lat\": vehicle_positions_df[\"latitude\"].mean(), \n",
    "                                     \"lon\": vehicle_positions_df[\"longitude\"].mean()},\n",
    "                      margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Main function to run the Dash app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True, port=8050)"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# 11.5.2. Speed Analysis Over Network Segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed6eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11.5.2. Speed Analysis Over Network Segments\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "import folium as fl\n",
    "from folium.features import GeoJson, GeoJsonTooltip\n",
    "import branca.colormap as cm\n",
    "\n",
    "\n",
    "# SQL query to get the average speed per segment and geometry\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    AVG(s.distance_m / EXTRACT(EPOCH FROM (ts.end_time_actual - ts.start_time_actual)) * 3.6) AS speedKMH,\n",
    "    s.geometry,\n",
    "    ts.start_stop_id,\n",
    "    ts.end_stop_id\n",
    "    FROM tripSegments ts\n",
    "JOIN segments s\n",
    "ON ts.start_stop_id = s.start_stop_id AND ts.end_stop_id = s.end_stop_id\n",
    "WHERE ts.start_time_actual IS NOT NULL\n",
    "  AND EXTRACT(EPOCH FROM (ts.end_time_actual - ts.start_time_actual)) > 0\n",
    "GROUP BY s.geometry, ts.start_stop_id, ts.end_stop_id;\n",
    "\"\"\"\n",
    "\n",
    "# Function to fetch data from PostgreSQL and return a GeoDataFrame\n",
    "def fetch_segment_speed_data():\n",
    "    \"\"\"\n",
    "    Connects to PostgreSQL and fetches the average speed per segment.\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame containing the segments, speedKMH, and geometries.\n",
    "    \"\"\"\n",
    "    conn = psycopg.connect(host=db_host, port=db_port, dbname=db_name, user=db_user, password=db_pass)\n",
    "    \n",
    "    # Load the data into a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame.from_postgis(sql_query, conn, geom_col='geometry')\n",
    "    \n",
    "    conn.close()\n",
    "    return gdf\n",
    "\n",
    "# Function to create a color map based on speed\n",
    "def create_colormap(min_speed, max_speed):\n",
    "    \"\"\"\n",
    "    Creates a colormap from white (low speed) to red (high speed).\n",
    "\n",
    "    Parameters:\n",
    "    - min_speed: The minimum speed for the color gradient.\n",
    "    - max_speed: The maximum speed for the color gradient.\n",
    "\n",
    "    Returns:\n",
    "    - A colormap function.\n",
    "    \"\"\"\n",
    "    return cm.LinearColormap(['red', 'white'], vmin=min_speed, vmax=max_speed) #faster segments are more white and slower segments are more red\n",
    "\n",
    "# Function to visualize the speed per segment using folium and GeoJSON\n",
    "def visualize_speed_map(gdf, cutoff=35):\n",
    "    \"\"\"\n",
    "    Visualizes the average speed per segment on a folium map using GeoJSON.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf: GeoDataFrame containing the segment geometries and speedKMH.\n",
    "    - cutoff: The maximum speed for the color gradient. Speeds above this are capped at the cutoff.\n",
    "    \n",
    "    Returns:\n",
    "    - A folium map with segments color-coded by speedKMH.\n",
    "    \"\"\"\n",
    "    # Create a folium map centered around the area\n",
    "    transport_map = fl.Map(location=[56.9496, 24.1052], zoom_start=12)\n",
    "\n",
    "    # Create a colormap for speed values\n",
    "    min_speed = gdf['speedkmh'].min()\n",
    "    max_speed = min(gdf['speedkmh'].max(), cutoff)  # Apply cutoff to the maximum speed\n",
    "    colormap = create_colormap(min_speed, max_speed)\n",
    "\n",
    "    # Add each segment to the map\n",
    "    for _, segment in gdf.iterrows():\n",
    "        # Apply cutoff to the speed\n",
    "        speed_kmh = min(segment['speedkmh'], cutoff)\n",
    "\n",
    "        # Get color based on speed\n",
    "        color = colormap(speed_kmh)\n",
    "\n",
    "        # Convert the geometry to GeoJSON with associated properties\n",
    "        geo_json = GeoJson(\n",
    "            data={\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": segment['geometry'].__geo_interface__,\n",
    "                \"properties\": {\n",
    "                    \"speedkmh\": round(segment['speedkmh'], 2),\n",
    "                    \"from_stop_id\": segment['start_stop_id'],\n",
    "                    \"to_stop_id\": segment['end_stop_id']\n",
    "                }\n",
    "            },\n",
    "            style_function=lambda x, color=color: {\n",
    "                'color': color,\n",
    "                'weight': 3,\n",
    "                'opacity': 0.7\n",
    "            },\n",
    "            tooltip=GeoJsonTooltip(\n",
    "                fields=['speedkmh', 'from_stop_id', 'to_stop_id'],\n",
    "                aliases=['Speed (km/h)', 'From Stop', 'To Stop'],\n",
    "                localize=True\n",
    "            )\n",
    "        )\n",
    "        geo_json.add_to(transport_map)\n",
    "\n",
    "    # Add the colormap to the map\n",
    "    colormap.add_to(transport_map)\n",
    "\n",
    "    return transport_map\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Fetch the segment speed data\n",
    "    segment_speed_gdf = fetch_segment_speed_data()\n",
    "\n",
    "    # Visualize the average speed per segment on a folium map\n",
    "    speed_map = visualize_speed_map(segment_speed_gdf)\n",
    "\n",
    "    # display the map\n",
    "    display(speed_map)"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d3cfdfb4",
   "metadata": {},
   "source": [
    "# 11.5.3 Delay Analysis in Public Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.5.3 Delay Analysis in Public Transport\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to connect to the PostgreSQL database\n",
    "def connect_to_postgres():\n",
    "    try:\n",
    "        conn = psycopg.connect(\n",
    "            host=db_host,\n",
    "            port=db_port,\n",
    "            dbname=db_name,\n",
    "            user=db_user,\n",
    "            password=db_pass\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        return conn, cur\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to PostgreSQL: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to fetch the delay data from the database\n",
    "def fetch_delay_data():\n",
    "    conn, cur = connect_to_postgres()\n",
    "    if conn is None or cur is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    query = \"\"\"\n",
    "    WITH noduptrip AS(\n",
    "\t  SELECT distinct(t.*) \n",
    "\t  FROM tripStops t),\n",
    "   tripDelay AS(\n",
    "        SELECT actual_trip_id, schedule_trip_id,\n",
    "            tgeompoint_Seq(array_agg(tgeompoint_inst(stop_loc, schedule_time) ORDER BY schedule_time)) AS schedule_trip,\n",
    "            tgeompoint_Seq(array_agg(tgeompoint_inst(trip_Geom, actual_time) ORDER BY actual_time)) AS actual_trip\n",
    "        FROM noduptrip\n",
    "        WHERE actual_trip_id like 'TROL4-%'\n",
    "        GROUP BY actual_trip_id, schedule_trip_id),\n",
    "    Final AS (SELECT actual_trip_id, schedule_trip_id, extract(EPOCH FROM actual - schedule)/60 as delay, actual AS t\n",
    "    FROM  (\n",
    "      SELECT actual_trip_id, schedule_trip_id,\n",
    "        unnest(timestamps(actual_trip)) AS actual,\n",
    "        unnest(timestamps(schedule_trip)) AS schedule\n",
    "      FROM tripDelay\n",
    "    ) x)\n",
    "    SELECT * \n",
    "    FROM Final\n",
    "    WHERE delay < 12;\n",
    "    \"\"\"\n",
    "    \n",
    "    cur.execute(query)\n",
    "    delay_data = pd.DataFrame(cur.fetchall(), columns=['actual_trip_id', 'schedule_trip_id', 'delay', 't'])\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return delay_data\n",
    "\n",
    "# Function to plot all trips on the same plot\n",
    "def plot_all_trips(delay_data):\n",
    "    \"\"\"\n",
    "    Plots all delay functions for each trip in one plot.\n",
    "    \n",
    "    Parameters:\n",
    "    - delay_data: DataFrame containing delay data for all trips\n",
    "    \"\"\"\n",
    "    # Create a line plot where color represents each trip\n",
    "    fig = px.line(delay_data, x='t', y='delay', color='actual_trip_id',\n",
    "                  title=\"\",\n",
    "                  labels={\"t\": \"Time\", \"delay\": \"Delay (minutes)\", \"actual_trip_id\": \"Trip ID\"},\n",
    "                  markers=True)\n",
    "    \n",
    "    # Customize the layout\n",
    "    fig.update_layout(xaxis_title=\"Time\", yaxis_title=\"Delay (minutes)\",\n",
    "                      xaxis=dict(tickformat=\"%H:%M:%S\"),\n",
    "                      template=\"plotly_white\")\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Fetch the delay data\n",
    "    delay_data = fetch_delay_data()\n",
    "    \n",
    "    if delay_data.empty:\n",
    "        print(\"No delay data found.\")\n",
    "    else:\n",
    "        # Step 2: Plot all delay functions in one plot\n",
    "        plot_all_trips(delay_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a873897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
